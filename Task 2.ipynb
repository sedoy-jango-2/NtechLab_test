{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2. ML\n",
    "\n",
    "## Описание задачи\n",
    "Необходимо обучить нейросеть, способную по входному изображению лица\n",
    "определять пол человека на изображении.\n",
    "\n",
    "## Описание решения\n",
    "### Описание процесса подготовки данных\n",
    "1. Загрузка данных с диска\n",
    "2. Конвертация 3-х канального изображения в одноканальное (GRAYSCALE)\n",
    "3. Изменение размеров изображений до стандартного 80 на 110\n",
    "4. Создание вектора ответов, где 0 - female, 1 - male\n",
    "5. Обхединение данных из папок male и female в один dataset\n",
    "6. Преобразование картинки в вектор признаков, где каждый пиксель будет являться признаком\n",
    "6. Нормализация признаков объектов\n",
    "7. Перемешивание данных\n",
    "8. Разбиение на обучающую и тестовую выборку в соотношении 70:30\n",
    "\n",
    "### Описание используемой нейронной сети\n",
    "В архитектуре финальной нейронной сети используется 2 сверточных слоя, а также GlobalAveragePooling2D. На выходе поставлена функция активации softmax, для предсказания вероятности принадлежности к каждому из классов.\n",
    "\n",
    "### Описание параметров обучения\n",
    "Количество epoch было подобрано исходя из сходимости нейронной сети и во избежание переобучения при большем значении epoch и недообучения при меньшем\n",
    "\n",
    "### Полученные результаты\n",
    "- Результат работы нейронной сети на обучающей выборке:  90.84298795748519\n",
    "- Результат работы нейронной сети на тестовой выборке:  88.680377321352\n",
    "\n",
    "### Инструкция по запуску тренировки\n",
    "Последовательно запустить все ячейки, предварительно разкоментировав данные строки:\n",
    "\n",
    "#model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "#history = model.fit(X_train, y_train, epochs=15)\n",
    "\n",
    "Данные необходимо разместить в папке с файлом notebook соответственно в internship_data/female и в internship_data/male\n",
    "\n",
    "### Инструкция по запуску нейронной сети\n",
    "python task_2.py [папка с картинками с расширением .jpg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from sklearn.utils import shuffle\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "import cv2, glob\n",
    "\n",
    "global inputShape, size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kerasModel4():\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(16, (8, 8), strides=(4, 4), padding='valid', input_shape=(sizeW,sizeH,1)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(32, (5, 5), padding=\"same\"))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(GlobalAveragePooling2D())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Dropout(.1))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(2))\n",
    "        model.add(Activation('softmax'))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeW = 80\n",
    "sizeH = 110\n",
    "\n",
    "# load data from female folder\n",
    "femaleImages = glob.glob(\"internship_data/female/*.jpg\")\n",
    "\n",
    "female_data_img = [cv2.imread(img, 0) for img in femaleImages]\n",
    "for i in range(0, len(female_data_img)):\n",
    "    female_data_img[i] = cv2.resize(female_data_img[i],(sizeW, sizeH))\n",
    "female_data = np.asarray(female_data_img)\n",
    "\n",
    "\n",
    "# load data from male folder\n",
    "maleImages = glob.glob(\"internship_data/male/*.jpg\")\n",
    "\n",
    "male_data_img = [cv2.imread(img, 0) for img in maleImages]\n",
    "for i in range(0, len(male_data_img)):\n",
    "    male_data_img[i] = cv2.resize(male_data_img[i],(sizeW, sizeH))\n",
    "male_data = np.asarray(male_data_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Формирование вектора ответов\n",
    "y_female = np.zeros([female_data.shape[0]],dtype = int)\n",
    "y_male = np.ones([male_data.shape[0]],dtype = int)\n",
    "\n",
    "y_data = []\n",
    "\n",
    "y_data.extend(y_female)\n",
    "y_data.extend(y_male)\n",
    "y_data = np.asarray(y_data)\n",
    "\n",
    "y_data = np_utils.to_categorical(y_data)\n",
    "\n",
    "# Формирование датасета\n",
    "X_data = []\n",
    "\n",
    "X_data.extend(female_data)\n",
    "X_data.extend(male_data)\n",
    "X_data = np.asarray(X_data)\n",
    "\n",
    "X_data = X_data.reshape(X_data.shape[0], sizeW, sizeH, 1)\n",
    "\n",
    "for data_point in X_data:\n",
    "    data_point = data_point / 255\n",
    "\n",
    "# Перемешивание данных\n",
    "X_data, y_data = shuffle(X_data, y_data)\n",
    "\n",
    "# Разделение на обучающую и тестовую выборку\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape X (70001, 80, 110, 1)\n",
      "Train shape y (70001, 2)\n",
      "Test shape X (30001, 80, 110, 1)\n",
      "Test shape y (30001, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape X\", X_train.shape)\n",
    "print(\"Train shape y\", y_train.shape)\n",
    "print(\"Test shape X\", X_test.shape)\n",
    "print(\"Test shape y\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    35139\n",
       "0.0    34862\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    15139\n",
       "1.0    14862\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3138: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/15\n",
      "70001/70001 [==============================] - 131s 2ms/step - loss: 0.5866 - acc: 0.6857\n",
      "Epoch 2/15\n",
      "70001/70001 [==============================] - 126s 2ms/step - loss: 0.4544 - acc: 0.7852\n",
      "Epoch 3/15\n",
      "70001/70001 [==============================] - 125s 2ms/step - loss: 0.3920 - acc: 0.8213\n",
      "Epoch 4/15\n",
      "70001/70001 [==============================] - 125s 2ms/step - loss: 0.3544 - acc: 0.8412\n",
      "Epoch 5/15\n",
      "70001/70001 [==============================] - 123s 2ms/step - loss: 0.3325 - acc: 0.8523\n",
      "Epoch 6/15\n",
      "70001/70001 [==============================] - 122s 2ms/step - loss: 0.3087 - acc: 0.8644\n",
      "Epoch 7/15\n",
      "70001/70001 [==============================] - 122s 2ms/step - loss: 0.2947 - acc: 0.8715\n",
      "Epoch 8/15\n",
      "70001/70001 [==============================] - 146s 2ms/step - loss: 0.2828 - acc: 0.8774\n",
      "Epoch 9/15\n",
      "70001/70001 [==============================] - 123s 2ms/step - loss: 0.2707 - acc: 0.8846\n",
      "Epoch 10/15\n",
      "70001/70001 [==============================] - 122s 2ms/step - loss: 0.2620 - acc: 0.8865\n",
      "Epoch 11/15\n",
      "70001/70001 [==============================] - 122s 2ms/step - loss: 0.2569 - acc: 0.8909\n",
      "Epoch 12/15\n",
      "70001/70001 [==============================] - 119s 2ms/step - loss: 0.2504 - acc: 0.8917\n",
      "Epoch 13/15\n",
      "70001/70001 [==============================] - 120s 2ms/step - loss: 0.2414 - acc: 0.8964\n",
      "Epoch 14/15\n",
      "70001/70001 [==============================] - 121s 2ms/step - loss: 0.2377 - acc: 0.8998\n",
      "Epoch 15/15\n",
      "70001/70001 [==============================] - 123s 2ms/step - loss: 0.2292 - acc: 0.9031\n",
      "70001/70001 [==============================] - 38s 548us/step\n",
      "Training Accuracy:  90.84298795748519 %\n",
      "30001/30001 [==============================] - 17s 550us/step\n",
      "Testing Accuracy:  88.680377321352 %\n"
     ]
    }
   ],
   "source": [
    "inputShape = (sizeW, sizeH, 1)\n",
    "model = kerasModel4()\n",
    "\n",
    "#model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "#history = model.fit(X_train, y_train, epochs=15)\n",
    "model = load_model('model.h5')\n",
    "\n",
    "metricsTrain = model.evaluate(X_train, y_train)\n",
    "print(\"Training Accuracy: \",metricsTrain[1]*100,\"%\")\n",
    "\n",
    "metricsTest = model.evaluate(X_test,y_test)\n",
    "print(\"Testing Accuracy: \",metricsTest[1]*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
